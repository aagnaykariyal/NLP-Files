{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 10 Lab:\n",
    "- Bag of Words\n",
    "- tf-idf\n",
    "- Euclidean Distance vs Cosine Similarity\n",
    "- Lab Explanation and Starting inClass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gensim: [Gensim](https://radimrehurek.com/gensim/auto_examples/index.html#documentation) is a free open-source Python library for representing documents as semantic vectors, as efficiently (computer-wise) and painlessly (human-wise) as possible. <br/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample text retrieved from Wikipedia:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-10T17:17:31.128342Z",
     "start_time": "2023-11-10T17:17:31.116636Z"
    }
   },
   "outputs": [],
   "source": [
    "txt = '''Neuro-linguistic programming (NLP) is a pseudoscientific approach to communication, \n",
    "personal development and psychotherapy, that first appeared in Richard Bandler and John Grinder's 1975 book The Structure of Magic I. \n",
    " NLP asserts that there is a connection between neurological processes (neuro-), language (linguistic) and acquired behavioral patterns (programming), \n",
    "and that these can be changed to achieve specific goals in life. According to Bandler and Grinder, NLP can treat problems such as phobias, depression, \n",
    "tic disorders, psychosomatic illnesses, near-sightedness, allergy, the common cold, and learning disorders, often in a single session. \n",
    "They also claim that NLP can model the skills of exceptional people, allowing anyone to acquire them.\n",
    "NLP has been adopted by some hypnotherapists, as well as by companies that run seminars marketed as leadership training to businesses and government agencies.\n",
    "There is no scientific evidence supporting the claims made by NLP advocates, and it has been called a pseudoscience. \n",
    "Scientific reviews have shown that NLP is based on outdated metaphors of the brain's inner workings that are inconsistent with current neurological theory, \n",
    "and contain numerous factual errors. Reviews also found that research that favored NLP contained significant methodological flaws, \n",
    "and that there were three times as many studies of a much higher quality that failed to reproduce the extraordinary claims made by Bandler, \n",
    "Grinder, and other NLP practitioners.'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-10T17:17:31.597455Z",
     "start_time": "2023-11-10T17:17:31.512770Z"
    }
   },
   "outputs": [],
   "source": [
    "# importing the needed libraries\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re \n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "from gensim import corpora\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenization (Revisted): Lets use sentence tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-10T17:17:33.178732Z",
     "start_time": "2023-11-10T17:17:33.158133Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[\"Neuro-linguistic programming (NLP) is a pseudoscientific approach to communication, \\npersonal development and psychotherapy, that first appeared in Richard Bandler and John Grinder's 1975 book The Structure of Magic I. \\n NLP asserts that there is a connection between neurological processes (neuro-), language (linguistic) and acquired behavioral patterns (programming), \\nand that these can be changed to achieve specific goals in life.\",\n 'According to Bandler and Grinder, NLP can treat problems such as phobias, depression, \\ntic disorders, psychosomatic illnesses, near-sightedness, allergy, the common cold, and learning disorders, often in a single session.',\n 'They also claim that NLP can model the skills of exceptional people, allowing anyone to acquire them.',\n 'NLP has been adopted by some hypnotherapists, as well as by companies that run seminars marketed as leadership training to businesses and government agencies.',\n 'There is no scientific evidence supporting the claims made by NLP advocates, and it has been called a pseudoscience.',\n \"Scientific reviews have shown that NLP is based on outdated metaphors of the brain's inner workings that are inconsistent with current neurological theory, \\nand contain numerous factual errors.\",\n 'Reviews also found that research that favored NLP contained significant methodological flaws, \\nand that there were three times as many studies of a much higher quality that failed to reproduce the extraordinary claims made by Bandler, \\nGrinder, and other NLP practitioners.']"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = nltk.sent_tokenize(txt)\n",
    "sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning: <br>\n",
    "1. Remove extra spaces\n",
    "2. Convert sentences to lower case\n",
    "3. Remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-10T17:29:18.029940Z",
     "start_time": "2023-11-10T17:29:18.006814Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean_sentence(sentence):\n",
    "    # Input : One sentence\n",
    "    # Process the sentence by keeping only letters, numbers and single spaces\n",
    "    # Converting sentence to lower case\n",
    "    # Removing stop words by using the remove stopwords function in Gensim\n",
    "    cleaned_sentence = re.sub(r'-', ' ', sentence)\n",
    "    cleaned_sentence = re.sub(r'[^a-zA-Z0-9 ]','',cleaned_sentence)\n",
    "    return remove_stopwords(cleaned_sentence.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting as input array of sentences and returning cleaned sentences array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-10T17:29:28.558399Z",
     "start_time": "2023-11-10T17:29:28.551898Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_cleaned_sentences(sent):\n",
    "    return [clean_sentence(line) for line in sent]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "['neuro linguistic programming nlp pseudoscientific approach communication personal development psychotherapy appeared richard bandler john grinders 1975 book structure magic nlp asserts connection neurological processes neuro language linguistic acquired behavioral patterns programming changed achieve specific goals life',\n 'according bandler grinder nlp treat problems phobias depression tic disorders psychosomatic illnesses near sightedness allergy common cold learning disorders single session',\n 'claim nlp model skills exceptional people allowing acquire',\n 'nlp adopted hypnotherapists companies run seminars marketed leadership training businesses government agencies',\n 'scientific evidence supporting claims nlp advocates called pseudoscience',\n 'scientific reviews shown nlp based outdated metaphors brains inner workings inconsistent current neurological theory contain numerous factual errors',\n 'reviews research favored nlp contained significant methodological flaws times studies higher quality failed reproduce extraordinary claims bandler grinder nlp practitioners']"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_data = get_cleaned_sentences(sentences)\n",
    "cleaned_data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-10T17:29:36.930974Z",
     "start_time": "2023-11-10T17:29:36.926460Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of Word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where all the unique words in the dictionary are organized as: <br>\n",
    "key: unique word and value: count/frequency<br>\n",
    "Then we are using function doc2bow which is used to create word embedding and storing all the word embedding to the corpus.<br>\n",
    "Dictionary is created organized in Asc order. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-10T17:44:17.643261Z",
     "start_time": "2023-11-10T17:44:17.640898Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{0: '1975',\n 1: 'according',\n 2: 'achieve',\n 3: 'acquire',\n 4: 'acquired',\n 5: 'adopted',\n 6: 'advocates',\n 7: 'agencies',\n 8: 'allergy',\n 9: 'allowing',\n 10: 'appeared',\n 11: 'approach',\n 12: 'asserts',\n 13: 'bandler',\n 14: 'based',\n 15: 'behavioral',\n 16: 'book',\n 17: 'brains',\n 18: 'businesses',\n 19: 'called',\n 20: 'changed',\n 21: 'claim',\n 22: 'claims',\n 23: 'cold',\n 24: 'common',\n 25: 'communication',\n 26: 'companies',\n 27: 'connection',\n 28: 'contain',\n 29: 'contained',\n 30: 'current',\n 31: 'depression',\n 32: 'development',\n 33: 'disorders',\n 34: 'errors',\n 35: 'evidence',\n 36: 'exceptional',\n 37: 'extraordinary',\n 38: 'factual',\n 39: 'failed',\n 40: 'favored',\n 41: 'flaws',\n 42: 'goals',\n 43: 'government',\n 44: 'grinder',\n 45: 'grinders',\n 46: 'higher',\n 47: 'hypnotherapists',\n 48: 'illnesses',\n 49: 'inconsistent',\n 50: 'inner',\n 51: 'john',\n 52: 'language',\n 53: 'leadership',\n 54: 'learning',\n 55: 'life',\n 56: 'linguistic',\n 57: 'magic',\n 58: 'marketed',\n 59: 'metaphors',\n 60: 'methodological',\n 61: 'model',\n 62: 'near',\n 63: 'neuro',\n 64: 'neurological',\n 65: 'nlp',\n 66: 'numerous',\n 67: 'outdated',\n 68: 'patterns',\n 69: 'people',\n 70: 'personal',\n 71: 'phobias',\n 72: 'practitioners',\n 73: 'problems',\n 74: 'processes',\n 75: 'programming',\n 76: 'pseudoscience',\n 77: 'pseudoscientific',\n 78: 'psychosomatic',\n 79: 'psychotherapy',\n 80: 'quality',\n 81: 'reproduce',\n 82: 'research',\n 83: 'reviews',\n 84: 'richard',\n 85: 'run',\n 86: 'scientific',\n 87: 'seminars',\n 88: 'session',\n 89: 'shown',\n 90: 'sightedness',\n 91: 'significant',\n 92: 'single',\n 93: 'skills',\n 94: 'specific',\n 95: 'structure',\n 96: 'studies',\n 97: 'supporting',\n 98: 'theory',\n 99: 'tic',\n 100: 'times',\n 101: 'training',\n 102: 'treat',\n 103: 'workings'}"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the list of words in the sentence\n",
    "sentences_words = [sentence.split() for sentence in cleaned_data]\n",
    "# Get the SORTED tokens, with ID of tokens set\n",
    "tokens = []\n",
    "for sentence in sentences_words:\n",
    "    tokens.extend(sentence)\n",
    "tokens = list(set(tokens))\n",
    "tokens.sort()  # It is always good practice to sort your tokens\n",
    "dictionary_tokens = {}\n",
    "for i in range(len(tokens)):\n",
    "    dictionary_tokens[i]=tokens[i]\n",
    "dictionary_tokens\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "data": {
      "text/plain": "{'1975': 0,\n 'achieve': 1,\n 'acquired': 2,\n 'appeared': 3,\n 'approach': 4,\n 'asserts': 5,\n 'bandler': 6,\n 'behavioral': 7,\n 'book': 8,\n 'changed': 9,\n 'communication': 10,\n 'connection': 11,\n 'development': 12,\n 'goals': 13,\n 'grinders': 14,\n 'john': 15,\n 'language': 16,\n 'life': 17,\n 'linguistic': 18,\n 'magic': 19,\n 'neuro': 20,\n 'neurological': 21,\n 'nlp': 22,\n 'patterns': 23,\n 'personal': 24,\n 'processes': 25,\n 'programming': 26,\n 'pseudoscientific': 27,\n 'psychotherapy': 28,\n 'richard': 29,\n 'specific': 30,\n 'structure': 31,\n 'according': 32,\n 'allergy': 33,\n 'cold': 34,\n 'common': 35,\n 'depression': 36,\n 'disorders': 37,\n 'grinder': 38,\n 'illnesses': 39,\n 'learning': 40,\n 'near': 41,\n 'phobias': 42,\n 'problems': 43,\n 'psychosomatic': 44,\n 'session': 45,\n 'sightedness': 46,\n 'single': 47,\n 'tic': 48,\n 'treat': 49,\n 'acquire': 50,\n 'allowing': 51,\n 'claim': 52,\n 'exceptional': 53,\n 'model': 54,\n 'people': 55,\n 'skills': 56,\n 'adopted': 57,\n 'agencies': 58,\n 'businesses': 59,\n 'companies': 60,\n 'government': 61,\n 'hypnotherapists': 62,\n 'leadership': 63,\n 'marketed': 64,\n 'run': 65,\n 'seminars': 66,\n 'training': 67,\n 'advocates': 68,\n 'called': 69,\n 'claims': 70,\n 'evidence': 71,\n 'pseudoscience': 72,\n 'scientific': 73,\n 'supporting': 74,\n 'based': 75,\n 'brains': 76,\n 'contain': 77,\n 'current': 78,\n 'errors': 79,\n 'factual': 80,\n 'inconsistent': 81,\n 'inner': 82,\n 'metaphors': 83,\n 'numerous': 84,\n 'outdated': 85,\n 'reviews': 86,\n 'shown': 87,\n 'theory': 88,\n 'workings': 89,\n 'contained': 90,\n 'extraordinary': 91,\n 'failed': 92,\n 'favored': 93,\n 'flaws': 94,\n 'higher': 95,\n 'methodological': 96,\n 'practitioners': 97,\n 'quality': 98,\n 'reproduce': 99,\n 'research': 100,\n 'significant': 101,\n 'studies': 102,\n 'times': 103}"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Doing the same above code cell task using Gensim\n",
    "dictionary = corpora.Dictionary(sentences_words)\n",
    "dictionary.token2id"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-10T17:41:44.926589Z",
     "start_time": "2023-11-10T17:41:44.918241Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking content of dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-10T17:46:32.734711Z",
     "start_time": "2023-11-10T17:46:32.725067Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neuro linguistic programming nlp pseudoscientific approach communication personal development psychotherapy appeared richard bandler john grinders 1975 book structure magic nlp asserts connection neurological processes neuro language linguistic acquired behavioral patterns programming changed achieve specific goals life\n",
      "[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 2), (19, 1), (20, 2), (21, 1), (22, 2), (23, 1), (24, 1), (25, 1), (26, 2), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1)]\n",
      "according bandler grinder nlp treat problems phobias depression tic disorders psychosomatic illnesses near sightedness allergy common cold learning disorders single session\n",
      "[(6, 1), (22, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (37, 2), (38, 1), (39, 1), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1), (46, 1), (47, 1), (48, 1), (49, 1)]\n",
      "claim nlp model skills exceptional people allowing acquire\n",
      "[(22, 1), (50, 1), (51, 1), (52, 1), (53, 1), (54, 1), (55, 1), (56, 1)]\n",
      "nlp adopted hypnotherapists companies run seminars marketed leadership training businesses government agencies\n",
      "[(22, 1), (57, 1), (58, 1), (59, 1), (60, 1), (61, 1), (62, 1), (63, 1), (64, 1), (65, 1), (66, 1), (67, 1)]\n",
      "scientific evidence supporting claims nlp advocates called pseudoscience\n",
      "[(22, 1), (68, 1), (69, 1), (70, 1), (71, 1), (72, 1), (73, 1), (74, 1)]\n",
      "scientific reviews shown nlp based outdated metaphors brains inner workings inconsistent current neurological theory contain numerous factual errors\n",
      "[(21, 1), (22, 1), (73, 1), (75, 1), (76, 1), (77, 1), (78, 1), (79, 1), (80, 1), (81, 1), (82, 1), (83, 1), (84, 1), (85, 1), (86, 1), (87, 1), (88, 1), (89, 1)]\n",
      "reviews research favored nlp contained significant methodological flaws times studies higher quality failed reproduce extraordinary claims bandler grinder nlp practitioners\n",
      "[(6, 1), (22, 2), (38, 1), (70, 1), (86, 1), (90, 1), (91, 1), (92, 1), (93, 1), (94, 1), (95, 1), (96, 1), (97, 1), (98, 1), (99, 1), (100, 1), (101, 1), (102, 1), (103, 1)]\n"
     ]
    }
   ],
   "source": [
    "## Gensim doc2bow\n",
    "corpus = [dictionary.doc2bow(sentence_tokens) for sentence_tokens in sentences_words]\n",
    "for sent, embedding in zip(cleaned_data, corpus):\n",
    "    print(sent)\n",
    "    print(embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the TF-IDF vector we are going to use TfidfVectorizer from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-10T17:49:50.217511Z",
     "start_time": "2023-11-10T17:49:50.189925Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<7x104 sparse matrix of type '<class 'numpy.float64'>'\n\twith 117 stored elements in Compressed Sparse Row format>"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidfvectorizer = TfidfVectorizer()\n",
    "tfidfvectorizer.fit(cleaned_data)\n",
    "tfidf_vectors = tfidfvectorizer.transform(cleaned_data)\n",
    "tfidf_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the above line of 7 is the number of documents and 104 is the number of words"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-10T17:50:40.664020Z",
     "start_time": "2023-11-10T17:50:40.650978Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array(['1975', 'according', 'achieve', 'acquire', 'acquired', 'adopted',\n       'advocates', 'agencies', 'allergy', 'allowing', 'appeared',\n       'approach', 'asserts', 'bandler', 'based', 'behavioral', 'book',\n       'brains', 'businesses', 'called', 'changed', 'claim', 'claims',\n       'cold', 'common', 'communication', 'companies', 'connection',\n       'contain', 'contained', 'current', 'depression', 'development',\n       'disorders', 'errors', 'evidence', 'exceptional', 'extraordinary',\n       'factual', 'failed', 'favored', 'flaws', 'goals', 'government',\n       'grinder', 'grinders', 'higher', 'hypnotherapists', 'illnesses',\n       'inconsistent', 'inner', 'john', 'language', 'leadership',\n       'learning', 'life', 'linguistic', 'magic', 'marketed', 'metaphors',\n       'methodological', 'model', 'near', 'neuro', 'neurological', 'nlp',\n       'numerous', 'outdated', 'patterns', 'people', 'personal',\n       'phobias', 'practitioners', 'problems', 'processes', 'programming',\n       'pseudoscience', 'pseudoscientific', 'psychosomatic',\n       'psychotherapy', 'quality', 'reproduce', 'research', 'reviews',\n       'richard', 'run', 'scientific', 'seminars', 'session', 'shown',\n       'sightedness', 'significant', 'single', 'skills', 'specific',\n       'structure', 'studies', 'supporting', 'theory', 'tic', 'times',\n       'training', 'treat', 'workings'], dtype=object)"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidfvectorizer.get_feature_names_out()  # Gives you a list of all the features present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 0 TFIDF Vector: [[0.15832198 0.         0.15832198 0.         0.15832198 0.\n",
      "  0.         0.         0.         0.         0.15832198 0.15832198\n",
      "  0.15832198 0.11233417 0.         0.15832198 0.15832198 0.\n",
      "  0.         0.         0.15832198 0.         0.         0.\n",
      "  0.         0.15832198 0.         0.15832198 0.         0.\n",
      "  0.         0.         0.15832198 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.15832198 0.         0.         0.15832198 0.         0.\n",
      "  0.         0.         0.         0.15832198 0.15832198 0.\n",
      "  0.         0.15832198 0.31664395 0.15832198 0.         0.\n",
      "  0.         0.         0.         0.31664395 0.13142084 0.13269275\n",
      "  0.         0.         0.15832198 0.         0.15832198 0.\n",
      "  0.         0.         0.15832198 0.31664395 0.         0.15832198\n",
      "  0.         0.15832198 0.         0.         0.         0.\n",
      "  0.15832198 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.15832198 0.15832198\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Document 0 TFIDF Vector: {tfidf_vectors[0].toarray()}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-10T17:52:38.471191Z",
     "start_time": "2023-11-10T17:52:38.446493Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "To find the distance between two vectors we can either: \n",
    "- Calculate Euclidean Distance (The higher, less similar. not sufficient)\n",
    "- Calculate Cosine Similarity (The higher, more similar, sufficient)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-10T17:56:37.666685Z",
     "start_time": "2023-11-10T17:56:37.650444Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104 104\n"
     ]
    }
   ],
   "source": [
    "## Getting two vectors from the tfidfvectorizer\n",
    "vector1 = tfidf_vectors[0].copy().toarray()\n",
    "vector2 = tfidf_vectors[1].copy().toarray()\n",
    "print(len(vector1[0]), len(vector2[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-10T17:58:22.139891Z",
     "start_time": "2023-11-10T17:58:22.113285Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance between vectors 1 and 2 is  1.393361559731348\n"
     ]
    }
   ],
   "source": [
    "## Calculate the Euclidean distance\n",
    "vector_diff = vector1 - vector2\n",
    "euclidean_distance = np.linalg.norm(vector_diff)\n",
    "print(\"Distance between vectors 1 and 2 is \", euclidean_distance)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
