{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-03T00:29:14.646173Z",
     "start_time": "2024-01-03T00:29:04.069971Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "from reddit import RedditClass  # Importing the reddit file\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import torch\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model_data = pd.read_json('sentiment_data.json', lines=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T00:29:14.710286Z",
     "start_time": "2024-01-03T00:29:14.622762Z"
    }
   },
   "id": "be96712ebc8a7d12",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "\n",
    "def stemming(sent):\n",
    "    texts = sent.lower()\n",
    "    texts = re.sub('[^a-z0-9]', ' ', texts)\n",
    "    texts = texts.split()\n",
    "    texts = [stemmer.stem(x) for x in texts if x not in stopwords.words('english')]\n",
    "    texts = ' '.join(texts)\n",
    "    return texts\n",
    "\n",
    "model_data['stemmed_data'] = model_data['Sentences'].apply(stemming)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T00:29:45.314051Z",
     "start_time": "2024-01-03T00:29:15.987215Z"
    }
   },
   "id": "2b38e217788a584d",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "x = model_data['stemmed_data'].values\n",
    "y = model_data['Sentiment'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2,stratify=y, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T00:29:46.569069Z",
     "start_time": "2024-01-03T00:29:46.543439Z"
    }
   },
   "id": "46c0b47f6bcb2cdd",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "array(['countri buy speaker', 'use work recent start issu',\n       'metallica repress led zepplin repress press palla germani freak good',\n       ..., 'return one skip',\n       'turntabl built pre amp connect directli power speaker via rca aux cabl',\n       'recent audit dali opticon 6 sonu faber lumina v new floor replac one'],\n      dtype=object)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T00:29:54.992099Z",
     "start_time": "2024-01-03T00:29:54.931603Z"
    }
   },
   "id": "7edb2720f594b1a",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1157, 5495)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T00:30:53.780115Z",
     "start_time": "2024-01-03T00:30:53.754537Z"
    }
   },
   "id": "1418aa3657561a65",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Converting textual data into numerical data\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T00:30:06.455610Z",
     "start_time": "2024-01-03T00:30:06.297255Z"
    }
   },
   "id": "cd4992ad07d6a3b6",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 4627)\t0.3191841043847163\n",
      "  (0, 1610)\t0.8132933961418256\n",
      "  (0, 1284)\t0.4864929180370689\n",
      "  (1, 5392)\t0.421646115736518\n",
      "  (1, 5166)\t0.33159045609313414\n",
      "  (1, 4692)\t0.42742835943044455\n",
      "  (1, 4061)\t0.5267560938779224\n",
      "  (1, 2809)\t0.502090965492635\n",
      "  (2, 3861)\t0.33581217576263456\n",
      "  (2, 3248)\t0.5380839089854487\n",
      "  (2, 2977)\t0.4542667487394492\n",
      "  (2, 2432)\t0.2701299023685451\n",
      "  (2, 2319)\t0.564240592599075\n",
      "  (3, 2144)\t0.7071067811865476\n",
      "  (3, 1570)\t0.7071067811865476\n",
      "  (4, 5040)\t0.39196349774781053\n",
      "  (4, 5009)\t0.3737931191306791\n",
      "  (4, 4409)\t0.21489377475691307\n",
      "  (4, 2934)\t0.39196349774781053\n",
      "  (4, 2177)\t0.34273065171656186\n",
      "  (4, 1073)\t0.3737931191306791\n",
      "  (4, 735)\t0.22087780621298883\n",
      "  (4, 89)\t0.28877621454833124\n",
      "  (4, 64)\t0.34273065171656186\n",
      "  (5, 5405)\t0.28242397972951716\n",
      "  :\t:\n",
      "  (1153, 860)\t0.3601112385509273\n",
      "  (1154, 4510)\t0.7083641606020835\n",
      "  (1154, 4161)\t0.5873996249727315\n",
      "  (1154, 3550)\t0.39138458906349416\n",
      "  (1155, 5219)\t0.33640747961629097\n",
      "  (1155, 5063)\t0.20426681414750472\n",
      "  (1155, 4627)\t0.1618037702557806\n",
      "  (1155, 4041)\t0.31076199741002475\n",
      "  (1155, 3843)\t0.3207465570901264\n",
      "  (1155, 3834)\t0.25567821611473873\n",
      "  (1155, 1826)\t0.3770707797628649\n",
      "  (1155, 1552)\t0.2561074512866421\n",
      "  (1155, 1299)\t0.2975808986354171\n",
      "  (1155, 1270)\t0.2869182505549545\n",
      "  (1155, 922)\t0.35074356602815365\n",
      "  (1155, 774)\t0.22897810094497442\n",
      "  (1156, 4595)\t0.41832419446017133\n",
      "  (1156, 4129)\t0.26342624087432365\n",
      "  (1156, 4061)\t0.2938440053802995\n",
      "  (1156, 3550)\t0.19138586531050614\n",
      "  (1156, 3421)\t0.21119596550985645\n",
      "  (1156, 2265)\t0.2994772756971197\n",
      "  (1156, 2158)\t0.41832419446017133\n",
      "  (1156, 1698)\t0.41832419446017133\n",
      "  (1156, 908)\t0.3851726848588452\n"
     ]
    }
   ],
   "source": [
    "print(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T00:30:17.832712Z",
     "start_time": "2024-01-03T00:30:17.814538Z"
    }
   },
   "id": "c16b28b2693ec3ff",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Creating the Logistic Regression model\n",
    "\n",
    "log_model = MultinomialNB()\n",
    "log_model.fit(X_train, y_train)\n",
    "\n",
    "# Getting model accuracy\n",
    "X_train_pred = log_model.predict(X_train)\n",
    "accuracy = accuracy_score(y_train, X_train_pred)\n",
    "print(f'The accuracy score of the training data is: {accuracy}')\n",
    "\n",
    "X_test_pred = log_model.predict(X_test)\n",
    "accuracy_scr = accuracy_score(y_test, X_test_pred)\n",
    "print(f'The accuracy of the test model is: {accuracy_scr}')\n",
    "\n",
    "check3 = 0\n",
    "while check3 == 0:\n",
    "    match input('Do you want to save the model? ').lower():\n",
    "        case 'y':\n",
    "            pickle.dump(model, open('SentimentModel.pkl', 'wb'))\n",
    "            check3 = 1\n",
    "        case \"n\":\n",
    "            check3 = 1\n",
    "            continue\n",
    "        case _:\n",
    "            print('Invalid input, Try again.')\n",
    "\n",
    "inp = input('Enter your sentence: ')\n",
    "res = stemming(inp)\n",
    "\n",
    "document = vectorizer.fit_transform([inp])\n",
    "#\n",
    "# prediction = log_model.predict(document)\n",
    "#\n",
    "print(document)\n",
    "x_new = X_test[1]\n",
    "print(x_new)\n",
    "print(y_test[1])\n",
    "\n",
    "# # prediction = log_model.predict(x_new)\n",
    "# print(prediction)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6e004721f245eed5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
