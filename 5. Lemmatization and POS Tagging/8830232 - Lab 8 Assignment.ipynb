{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab8 Assignment Task PROG8245 - NLP Introduction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name: Aagnay Kariyal\n",
    "### ID: 8830232"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the discussed topic in class for tokenizers, stop-word removal, stemming/lemmatization, and POS Tagging. <br><br>\n",
    "Create **ONE** function, that takes as an input a string, and returns the output of a string after stemming/lemmatization.<br><br>\n",
    "**Kindly note that you are required to consider the POS Tag while doing your stemming or lemmatization step (you should use whatever is more suitable for this task)** <br><br>\n",
    "After creating the function, you need to run your function on 10 **Random** files from reuters corpus, an example of how to download and load a file of reuters corpus is below. <br><br>\n",
    "**Your 10 **Random** files should be retrieved by getting a random array of length 10 which picks numbers RANDOMLY from 0 to len(reuters.fileids()), then the elements retrieved will be your corpus.<br> <br>*You need to set your Seed to be Equal to the last 3 digits in your studentID.*<br>** If your ID is 8000888 then seed =888 <br>\n",
    "**You may need to tailor your task based on the dataset to remove some special characters.**\n",
    " "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Last Step\n",
    "After finishing your code, run your code and save the result in a python dictionary, which would be of format:<br>\n",
    "{DocumentID: [List of Words], <br>\n",
    "...} <br>\n",
    "Save your python dictionary as a JSON file, or Pickle file. <br>\n",
    "A sample code for saving a python dictionary is available at the end of this notebook.<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "# Importing all the necessary dependencies\n",
    "import nltk\n",
    "import random\n",
    "import string\n",
    "import json\n",
    "from nltk.corpus import reuters\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-09T22:38:05.189818Z",
     "start_time": "2023-11-09T22:38:05.181148Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T20:54:51.378348Z",
     "start_time": "2023-11-09T20:54:51.371981Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package reuters to\n",
      "[nltk_data]     /Users/aagnaykariyal/nltk_data...\n",
      "[nltk_data]   Package reuters is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "[3031, 2515, 868, 9227, 2932, 3028, 10163, 4514, 5396, 1318]"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('reuters') #downloading reuters corpus\n",
    "stop = len(reuters.fileids()) #checking how many files are there\n",
    "random.seed(232) # Seed set to the last 3 digits of my student number.\n",
    "array = random.choices(range(0, stop), k=10) # Creating an array of document ids\n",
    "array # Checking for the ids present inside the list"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Since some of the document ids that I randomly generated according to my student id is not present inside the reuters package, im manually setting the ids to be the next closest value. I manually checked the folder and I was not able to find the files corresponding to the IDs."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "# Manually setting the ids for the one that are not present in the reuters folder\n",
    "array[3] = 9228\n",
    "array[4] = 2933\n",
    "array[9] = 1317"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-09T21:02:55.678481Z",
     "start_time": "2023-11-09T21:02:55.665948Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3031, 2515, 868, 9228, 2933, 3028, 10163, 4514, 5396, 1317]\n"
     ]
    }
   ],
   "source": [
    "print(array) # Printing to check if the values have changed"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-09T21:02:55.754067Z",
     "start_time": "2023-11-09T21:02:55.751743Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T21:15:53.115927Z",
     "start_time": "2023-11-09T21:15:53.104360Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'document_ids': [3031, 2515, 868, 9228, 2933, 3028, 10163, 4514, 5396, 1317], 'texts': ['BONN SERIOUS ABOUT CURRENCY PACT, SAYS TIETMEYER\\n  West Germany takes \"very seriously\" the\\n  recent undertaking by major industrial countries to promote\\n  exchange rate stability around current levels, Finance Ministry\\n  State Secretary Hans Tietmeyer said.\\n      Talking to journalists before a meeting of European\\n  Community Economy and Finance Ministers here, Tietmeyer\\n  declined to say whether the February 22 Paris accord by the\\n  Group of Five countries plus Canada included secret agreements\\n  for stabilising currencies.\\n      But he noted the official communique said the participants\\n  agreed to cooperate closely to foster stability of exchange\\n  rates around current levels. \"We\\'re taking this sentence very\\n  seriously,\" he said.\\n      Tietmeyer remarked that the dollar had hardly moved against\\n  the mark since the meeting.\\n      He said a slowdown in West German economic growth had been\\n  caused by sharp exchange rate swings and that the Paris\\n  agreement should help in this respect.\\n      Economics Ministry State Secretary Otto Schlecht said the\\n  Bonn government saw no current need for measures to bolster the\\n  economy but was paying close attention to the slower growth and\\n  had not ruled out \"appropriate and timely\" action if necessary.\\n      Schlecht and Tietmeyer were speaking ahead of a discussion\\n  by the EC ministers of the latest EC Commission report on the\\n  economic situation in the 12-nation bloc.\\n      The Commission has sharply revised down expected German\\n  gross national product growth this year to two pct from 3.2 pct\\n  predicted last autumn and says Bonn has the most room of any EC\\n  country to stimulate economic activity.\\n      Schlecht said the upturn in West Germany\\'s economy slowed\\n  in the fourth quarter of last year and the first quarter of\\n  1987. But he said there was no cumulative downwards trend in\\n  view that would make quick remedial action necessary.\\n      He said a number of favourable indicators such as high\\n  level of investment and a good climate for consumption meant a\\n  recovery could be expected, while exports would pick up\\n  slightly during the course of the year.\\n  \\n\\n', 'SOUTH AFRICAN FIRM TO CONTINUE TESTS\\n  South Africa\\'s state-owned energy\\n  firm Soekor said it would continue tests after striking oil\\n  some 120 kms (75 miles) south-southwest of Mossel Bay.\\n      During production tests, about 5,000 barrels of oil and\\n  five mln cubic feet of gas per day were produced, it said.\\n      \"This oil discovery will be followed-up as soon as possible\\n  by further seismic surveys and drilling. Should further\\n  drilling and tests in the area yield positive results oil\\n  production from a floating platform could be considered.\"\\n      Director General of Mineral and Energy Affairs Louw Alberts\\n  announced the strike earlier but said it was uneconomic.\\n  \\n\\n', \"FORD &lt;F> EUROPE EARNINGS UP 71 PCT LAST YEAR\\n  Ford Europe's net earnings soared by 71\\n  per cent last year to 559 mln dlrs, Kenneth Whipple, chairman\\n  of Ford Europe, said.\\n      Whipple, here to attend the Geneva Auto Show which opens on\\n  Thursday, said that the Ford Motor Co unit had sold a record\\n  1.5 million vehicles in Europe in 1986.\\n      Net earnings were 326 mln dlrs in 1985.\\n      Sales in 1986 represented 11.8 per cent of the European\\n  market share, Whipple said. Ford will invest 1.2 billion\\n  dollars in Europe in 1987, and a total of seven billion over\\n  the next seven years, he added.\\n  \\n\\n\", '25-MAR-1987\\n  25-MAR-1987\\n\\n', 'MONOCLONAL ANTIBODIES &lt;MABS> BUYS COMPANY\\n  Monoclonal Antibodies Inc\\n  said it signed an agreement in principle to buy &lt;Genesis Labs\\n  Inc> for about 10 mln dlrs of common stock.\\n      The agreement is subject to shareholders approval and other\\n  conditions.\\n  \\n\\n', 'BRAZIL SEAMEN CONTINUE STRIKE DESPITE COURT\\n  Hundreds of marines were on alert\\n  at 11 key Brazilian ports after 40,000 seamen decided to remain\\n  on indefinite strike, even after the Higher Labour Court\\n  Saturday ruled it illegal, union leaders said.\\n      The halt, the first national strike by seamen in 25 years,\\n  started on February 27, and union leaders said they would not\\n  return to work unless they got a 275 pct pay rise. Shipowners\\n  have offered a 100 per cent raise, which the seamen rejected.\\n      \"We have nothing to lose. If they want to lay off the\\n  workers, fine, but we are determined to carry on with our\\n  protest until the end,\" a union leader said.\\n   more\\n      He said they had decided in a meeting that if the marines\\n  take over the ships, the seamen would abandon the vessels and\\n  let the marines handle the situation by themselves.\\n      A spokesman for the Rio de Janeiro Port said the order to\\n  send marines to take over the ports was given by Navy Minister\\n  Henrique Saboya on grounds that ports are areas of national\\n  security. But he said there were no incidents. The strike has\\n  cut exports and imports and made an estimated 160 ships idle.\\n      Petrol station owners in four states also continued their\\n  shutdown and there were fears that the combination of the two\\n  stoppages could lead to a serious fuel shortage.\\n  \\n\\n', 'EQUITABLE RESOURCES INC &lt;EQT> IN REGULAR PAYOUT\\n  Qtly div 30 cts vs 30 cts prior\\n      Pay June one\\n      Record May eight\\n      NOTE: Current dividend is equivalent to previous quarterly\\n  dividend of 45 cts per share, after giving effect to 3-for-2\\n  stock split effective March 3, 1987.\\n  \\n\\n', 'IOWA BEEF LIFTS LOCKOUT AT DAKOTA CITY\\n  Iowa Beef Processors Inc is lifting a\\n  lockout at its Dakota City, Nebraska, processing plant and\\n  plans to resume operations March 16, United Food and Commercial\\n  Workers (UFCW) Union spokesman Allen Zack said.\\n      Iowa Beef mailed a letter to members of UFCW Local 222\\n  informing them a lockout imposed by the company December 14\\n  would be lifted and meatpackers could return to work under Iowa\\n  Beef\\'s \"revised, last and best final offer,\" Zack said.\\n      Iowa Beef had closed the plant indefinitely in mid-December\\n  because it said it had no alternative to threats by meatpackers\\n  to disrupt operations.\\n      About 2,800 members of Local 222 are affected by the\\n  shutdown. A 3-1/2 year labor contract at the plant expired\\n  December 13.\\n  \\n\\n', 'INTERMAGNETICS GENERAL &lt;INMA> COMPLETES BUY\\n  Intermagnetics General Corp\\n  said it completed the purchase of the advanced products\\n  department of Air Products and Chemicals Inc &lt;APD>.\\n      Terms were not disclosed.\\n      The department, which makes cryogenic equipment, will\\n  continue operating at its present location in Allentown, Pa.,\\n  the company said. It will market its products as APD Cryogenics\\n  Inc.\\n  \\n\\n', 'AMERICAN VANGUARD CORP &lt;AMGD> YEAR NET\\n  Shr 57 cts vs 27 cts\\n      Net 1,002,000 vs 470,000\\n      Sales 15.9 mln vs 12.0 mln\\n      Note: 4th qtr figures not given.\\n  \\n\\n']}\n"
     ]
    }
   ],
   "source": [
    "# to read specific file\n",
    "texts = [] # Creating a list to store all the text corpus\n",
    "# Creating a for loop to iterate through the document ids to save the text into a list\n",
    "for ids in array:\n",
    "    ids = str(ids)\n",
    "    document_id = 'training/'+ids # Getting the document using the id\n",
    "    text = reuters.raw(document_id) # Reading a sample file from reuters\n",
    "    texts.append(text) # Adding the texts into the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T16:47:39.423974Z",
     "start_time": "2023-11-16T16:47:39.415021Z"
    }
   },
   "outputs": [],
   "source": [
    "def nlp_lem(t): # Creating a function to do lemmatization and POS tagging\n",
    "    tokens = word_tokenize(t) # Tokenization\n",
    "    # Removing stop words\n",
    "    stop_words_removed = [word for word in tokens if word not in stopwords.words('english')]\n",
    "    # Creating a list of punctuations to remove\n",
    "    punctuation_list = list(string.punctuation)\n",
    "    # Saving the punctuations removed words into a list\n",
    "    punctuation_removed = [word for word in stop_words_removed if word not in punctuation_list]\n",
    "    # Creating a list to save all the double punctuation errors\n",
    "    double_punkt = []\n",
    "    # Creating a for loop to create the double punctuation errors so that we can cross-check with the main data to remove the errors from the main data.\n",
    "    for w in punctuation_list:\n",
    "        double_punkt.append(w+w)\n",
    "    # We save the cleaned data by checking for the error punctuations present inside the main data\n",
    "    punctuation_removed = [word for word in punctuation_removed if word not in double_punkt]\n",
    "    # Changing the case inside the list to normalize it\n",
    "    case_folded = [word.lower() for word in punctuation_removed]\n",
    "    \n",
    "    # Lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in case_folded]\n",
    "    \n",
    "    # POS Tagging and returning the values\n",
    "    return nltk.pos_tag(word_tokenize(\" \".join(lemmatized_words)))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving python dictionary with json:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "data_dict = {}\n",
    "for num in range(0, 10):\n",
    "    data_dict[str(array[num])] = nlp_lem(texts[num])\n",
    "    \n",
    "with open(\"pos.json\", \"w\") as output:\n",
    "    json.dump(data_dict, output)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-09T22:38:08.373281Z",
     "start_time": "2023-11-09T22:38:08.267746Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
